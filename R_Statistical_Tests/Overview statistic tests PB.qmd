---
title: "Overview statistic tests PB"  
author: "Jonas van Nijnatten"


format: 
  html: 
    page-layout: full
    max-width: 2000px
    body-width: 100%
    fig-width: 12
    embed-resources: true
    lightbox: true
    toc: true
    toc-depth: 4
    toc-float: true
    toc-location: right
    number-sections: true
    margin-left: 5px
    margin-right: 80px

  # pdf:
  #   fig_caption: true
  #   number_sections: true
  #   toc: true
  #   toc_depth: '2'
    
execute: 
  image-width: 1200px
knitr: 
  opts_chunk: 
    message: false
    warning: false 
    fig-show: hold
    results: hold    
    
pdf-engine-opts:
  - '-latex-auto-install= true'
 
header-includes:
- \usepackage{geometry}
- \geometry{a4paper, portrait, margin=.75in}
---



```{css, echo=FALSE, eval=FALSE}
body .main-container{
  max-width: 2500px;
  width: 100%;
  margin: 0;
 padding: 1em;
 line-height: 20px ; 
}   

body {
  max-width: 2500px;
  width: 100%;
  margin: 0;
 padding: 1em;
 line-height: 20px ; 
}   

#TOC {
  max-width: 280px;
  width: 20%;
}
```
contact: J.J.vanNijnatten@uva.nl

source code: https://github.com/jonasvannijnatten/PB_statistiek

laatste update: `r format.Date(Sys.Date(), '%d-%m-%Y')`

Other R manuals for Psychobiology: https://jonasvannijnatten.github.io/PB_statistiek/

***

\newpage

#   R and package versions
## Versions  
software versions used for this tutorial:  
 - `r R.Version()$version.string`   
 - car-package version: `r packageVersion("car")` (`r packageDate("car")`)  
 - lmerTest-package version: `r packageVersion("lmerTest")` (`r packageDate("lmerTest")`)
 - ez-package version:  `r packageVersion("ez")` (`r packageDate("ez")`)
 
##  Installation
Install & activate the required packages:
```{r}
#| label: "package installation"
#| echo: false
#| results: hide
#| message: false
#| warning: false
reqPacks = c("markdown","knitr","kableExtra","car","ez","afex", "ggplot2", "gridExtra","lmerTest","interactions","tidyverse", "performance","emmeans")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(reqPacks, character.only = TRUE)
print("Required packages")
print(cbind(reqPacks))
```

***

\newpage

#  T-test

## Independent samples T-test
<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r}
#| label: "indep Test data"
# generate data
N = 40
data.long = data.frame(
  ID = 1:N,
  condition = rep(x = c("A","B"), each = N),
  score = c(rnorm(n = N, mean = 25, sd = 6.5), rnorm(n = N, mean = 35, sd = 6.5))
)
```
</details>

```{r}
#| label: "show table"
#| echo: false
kable(data.long[c(1:5,41:45),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

Test assumption of normality
```{r}
by(data = data.long$score, INDICES = data.long$condition, FUN = shapiro.test)
```
Test assumption of equality of variances
```{r}
leveneTest(y = data.long$score, group = data.long$condition)
```
**T-test**
```{r}
summary(lm(formula = score ~ condition, data = data.long))
t.test(formula = score ~ condition, data = data.long, alternative="two.sided", var.equal=TRUE)
```

## Paired samples T-test
<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r}
# generate data
N = 30
data.long = data.frame(
  ID = rep(1:N,2),
  condition = rep(x = c("A","B"), each = N),
  score = c(rnorm(n = N, mean = 25, sd = 6.5), rnorm(n = N, mean = 35, sd = 6.5))
)
```
</details>

```{r,echo=FALSE}
kable(data.long[c(1:5,31:35),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

Test assumption of normality
```{r}
# calculate difference scores
diffScore = data.long$score[data.long$condition=="A"] - data.long$score[data.long$condition=="B"]
shapiro.test(diffScore)
```

**T-test**
```{r}
t.test(formula = score ~ 1, data = data.long, alternative="two.sided", var.equal=TRUE)
lmer(formula = score ~ condition+(1|ID), data = data.long)
```

***
\newpage

#  Correlation

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary> 
```{r}
# generate data
set.seed(05)
nrobs = 100
experience = rnorm(n = nrobs, mean = 15, sd = 3)
salary     = 10000 + ( 5 * experience ) + rnorm(n = nrobs, mean = 0, sd = 100)
data.long = data.frame(experience, salary)
# calculate correlation coefficient r
corr_coef = cor(x = data.long$experience, y = data.long$salary)
rm(list = c("nrobs", "experience", "salary"))
```
</details>   

```{r,echo=FALSE}
kable(data.long[1:5,], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```
Test assumption of normality
```{r}
apply(X = data.long, MARGIN = 2, FUN = shapiro.test)
```

**Pearson correlation**
```{r}
cor.test(x=data.long$experience, y=data.long$salary, alternative = "two.sided", method = "pearson")
```

**Spearman correlation**
```{r}
cor.test(x=data.long$experience, y=data.long$salary, alternative = "two.sided", method = "spearman")
```
 ***
 
\newpage 

# Regression

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary> 
```{r}
#| label: "simple regression data"
# generate data
set.seed(05)
nrobs = 100
experience = rnorm(n = nrobs, mean = 15, sd = 3)
salary     = 10000 + ( 5 * experience ) + rnorm(n = nrobs, mean = 0, sd = 100)
data.long = data.frame(experience, salary)
# calculate correlation coefficient r
corr_coef = cor(x = data.long$experience, y = data.long$salary)
rm(list = c("nrobs", "experience", "salary"))
```
</details>   

```{r}
#| label: "show data table"
#| echo: false
kable(data.long[1:5,], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

Fit linear model
```{r}
#| label: "simple regression model fit"
linearModel = lm(formula = salary ~ experience, data = data.long)
```

Test assumption of normality & equal variances
```{r}
#| label: "simple regression assumption checks"
check_model(linearModel)
```
**Regression test**
```{r}
#| label: "simple regression output"
summary(linearModel)
```


***  
\newpage

# Logistic regression

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary> 
```{r}
#| label: "logistic regression data"
set.seed(01)
N = 30
x = sort(runif(n = N, min = 0, max = 10))
y = round(
  1 / (1 + exp(-.5*x+(max(x)/4) + rnorm(N,0,1.5)))  # logistic function of x + noise
  ) # round it to either 1 or 0
data.long = data.frame(x = x, y = y)
```
</details>

```{r}
#| label: "logistic regression model fitting"
# fit a logistic model, which is a generalized linear model, hence glm() function
glm.fit <- glm(y ~ x, data = data.long, family = binomial('logit'))
# test the logistic model against the NULL model
summary(glm.fit)
```
```{r}
#| label: "Logistic regression plot"
ggplot(data.long, aes(x=x, y=y)) + geom_point() +
  stat_smooth(method="glm", color="blue", se=TRUE, 
              method.args = list(family=binomial)) +
  theme_classic()
```

***  
\newpage

#  One-way independent samples ANOVA
<details><summary><span style="color:dodgerBlue">Toon code om voorbeeld data te genereren </span></summary>
```{r}
#| label: "ANOVA data"
set.seed(05)   # set seed
nrofconds = 3  # set number of conditions
nrofsubs  = 20 # set number of subjects
subj = as.factor(1:(nrofsubs*nrofconds))      # create array with subject IDs
condition = as.factor(rep(LETTERS[1:nrofconds],each=nrofsubs))   # create array with condition values
score = as.vector( replicate(
          nrofconds , rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1) ) 
        ) )                                     # create array with measurement values
data.long = data.frame(subj, condition, score);      # combine arrays into a data.frame
rm(list=c("subj", "condition","score","nrofconds","nrofsubs")) # delete unnecessary variables

```   
</details>  
   
```{r}
#| label: "show data"
#| echo: false
kable(data.long[c(1:2,21:22,41:42),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Checking assumptions

Test assumption of normality
```{r}
by(data = data.long$score, INDICES = data.long$condition, FUN = shapiro.test)
```
Test equality of variances
```{r}
leveneTest(y = data.long$score, group = data.long$condition)
```


## Running the test {.tabset .tabset-pills}

:::{.panel-tabset}
### parametric methods {.tabset .tabset-pills}

::::{.panel-tabset}
#### using *lm()* (PB recommended) {.active}  

***ANOVA*** using the linear model method
```{r, message=FALSE}
lmModel = lm(formula = score ~ condition, data = data.long)
anova(lmModel)

# for post hoc comparison of conditions
emmeans::emmeans(lmModel, pairwise~condition)
```


#### using *ezANOVA()*
***ANOVA*** using the ezANOVA method
```{r, message=FALSE}
ezModel = ezANOVA(data = data.long, dv = score, between = condition, wid = subj)
ezModel$ANOVA
```



#### using *aov_ez()*
***ANOVA*** using the aov_ez() method
1. First we build the model using the *aov_ez()* function from the *afex* package.  
```{r, message=FALSE}
afexModel = aov_ez(data = data.long, id = "subj", dv = "score", between = "condition")
afexModel$anova_table
``` 
  

2. Next we test the assumption of normality for all the residuals in the model at once:
```{r, message=FALSE}
hist(afexModel$lm$residuals)
shapiro.test(afexModel$lm$residuals)
```

```{r, results='hide', fig.keep='all'}
# library(car)
qqPlot(afexModel$lm)
```  
  
3. Then we test the assumption of equal variences using Levene's Test:
```{r}
leveneTest(afexModel$lm)
```



#### using *aov()*
***ANOVA*** using the aov method
```{r, message=FALSE}
aovModel = aov(formula = score ~ condition, data = data.long)
summary(aovModel)
```

::::



### Non-parametric methods
```{r}
#| label: "Kruskal-Wallis"
#| message: false
kruskal.test(score~condition, data.long)
```

:::

## Post-hoc analysis

When using the aov method, use the Tukey post-hoc test
```{r}
TukeyHSD(aovModel)
```

When using the linear model method, use pairwise t-test
```{r}
pairwise.t.test(x = data.long$score, g = data.long$condition, paired = FALSE, p.adjust.method = "bonferroni")
```



***  
\newpage

#  Factorial independent samples ANOVA

<details><summary><span style="color:dodgerBlue">Show code for data generation</span></summary>
```{r, echo=TRUE}
set.seed(01)   # set seed
nrofcondsf1 = 3  # set number of conditions for factor 1
nrofcondsf2 = 2  # set number of conditions for factor 2
nrofsubs    = nrofcondsf1*nrofcondsf2*30 # set number of subjects per condition
subj = as.factor(1:(nrofsubs))      # create array with subject IDs
# create array witht treatment conditions
treatment = as.factor(rep(LETTERS[1:nrofcondsf1],each=nrofsubs/nrofcondsf1))   
# create array with control / experimental
control   = as.factor(rep(c("control","experimental"),times=nrofsubs/nrofcondsf2))   
# create array with measurement values
score = as.vector( replicate(nrofcondsf1, replicate ( 
          nrofcondsf2 , rnorm(
            n = (nrofsubs/(nrofcondsf1*nrofcondsf2)), 
            mean = 0 , sd = sample(5,1) ) + sample(8,1)+10
        ) ) )                             
# combine arrays into a data.frame
data.long = data.frame(subj, score, treatment, control);      
# delete unnecessary arrays
rm(list=c("control","nrofcondsf1","nrofcondsf2","nrofsubs","score","subj","treatment"))

```   
</details>     

```{r,echo=FALSE}
kable(data.long[c(1:2,61:62,121:122),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model

Fit model with multiple prediction factors
```{r}
model = lm(formula = score ~ treatment+control, data = data.long)
```

## Checking assumptions

Test assumption of normality
```{r, eval=FALSE}
hist(model$residuals)
plot(x = fitted(model), y = residuals(model), xlab="predicted", ylab="residuals"); abline(h=0)
by(data = data.long$score, INDICES = paste(data.long$treatment, data.long$control), FUN = shapiro.test)
```
<details><summary><span style="color:dodgerBlue">Show residuals histogram</span></summary>
```{r, echo=FALSE}
hist(model$residuals)
```
</details>
<details><summary><span style="color:dodgerBlue">Show residuals vs predicted plot</span></summary>
```{r, echo=FALSE}
plot(x = fitted(model), y = residuals(model), xlab="predicted", ylab="residuals"); abline(h=0)
```
</details>
<details><summary><span style="color:dodgerBlue">Show output of Shapiro-Wilk test</span></summary>
```{r, echo=FALSE}
by(data = data.long$score, INDICES = paste(data.long$treatment, data.long$control), FUN = shapiro.test)
```
</details>

Test equality of variances
```{r}
leveneTest(y = data.long$score, group = as.factor(paste(data.long$treatment, data.long$control)))
```

## Running the test

ANOVA with the linear model method
```{r}
model = lm(formula = score ~ treatment*control, data = data.long)
library(car)
Anova(mod = model, type = 'II')
summary(model)
```
\newpage 

## Post-hoc analysis

When there are one or more significant main-effects but no significant interaction effect post-hoc comparisons can be made for each factor separately using the pairwise.t.test() function.

Post-hoc comparison for the first factor:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$treatment          # column name of the first within-subjects variable
  , paired = FALSE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

Post-hoc comparison for the first factor:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$control           # column name of the second within-subjects variable
  , paired = FALSE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

When the interaction effect turns out significant, pairwise comparisons can be made between all combinations of conditions.

Post-hoc comparison for the interaction effect:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  # merge both factor columns into a combined factor
  ,g = paste(data.long$treatment, data.long$control)           
  , paired = FALSE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```


***  
\newpage  

#  One-way repeated measures ANOVA
<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r, echo=TRUE}
# Generate dataset
set.seed(01)   # set seed
nrofsubs  = 20 # set number of subjects
data.wide = data.frame(
  subj = as.factor(1:nrofsubs)   ,
  A =  rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1)) ,
  B =  rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1)) ,
  C =  rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1))
)
rm(list=c("nrofsubs")) # delete arrays

# reshape the data to the long format for some analysis methods
data.long = reshape(
  data = data.wide
  ,direction  = 'long'          # richting van de data-transformatie
  ,varying    = c('A','B','C')  # kolomnamen die worden samengevoegd
  ,idvar      = 'subj'          # kolomnaam met de ppn-nummers
  ,v.names    = 'score'         # naam van nieuwe kolom met meetwaarden
  ,timevar    = 'condition'     # naam van nieuwe kolom met condities
  ,times      = c('A','B','C')  # waardes 
  )
data.long$condition = as.factor(data.long$condition)
```
</details>  

```{r,echo=FALSE}
kable(data.wide[1:4,], row.names = FALSE, caption = 'data.wide') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")

kable(data.long[c(1:2,21:22,41:42),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model {.tabset .tabset-pills}

### Parametric Test  {.tabset .tabset-pills}

#### Using *ezAONVA*

1. First we fit the model using the *ezANOVA()* function:
```{r}
ezModel = ezANOVA(data = data.long, dv = score, wid = subj, within = condition)
```
  
2. Then we check for the assumption of normality. Because the model takes into account individual differences, we should first correct the individual score by removing the individual differences from the data.
We do this by calculating how each individual differes from the overall mean.

$corrected = Y_{i,j}corrected - (\overline{Yi} - \overline{Y})$  

where $i$ represents the individual subjects, and $j$ represents the different conditions

```{r, results='hold', warning=TRUE, fig.ncol=2}
# initialize variables to store calculate correted score
data.long$subjMean     = rep(NA, dim(data.long)[1])
data.long$correction   = rep(NA, dim(data.long)[1])
data.long$corrected    = rep(NA, dim(data.long)[1])

for (i in unique(data.long$subj)){
  # calculate the mean score for each subject (across conditions)
  data.long$subjMean[which(data.long$subj==i)] = mean(data.long$score[which(data.long$subj==i)])
  # calculate the correction as the difference between the subject mean vs the overall mean
  data.long$correction[which(data.long$subj==i)] = 
    (data.long$subjMean[which(data.long$subj==i)] - mean(data.long$score))
  # calculate the corrected score by subtracting the correction per subject from each individual score value
  data.long$corrected[which(data.long$subj==i)] = 
    data.long$score[which(data.long$subj==i)] - data.long$correction[which(data.long$subj==i)]
}


p1 = ggplot(data.long, aes(x=condition, y=score, group=1, colour=subj)) +
  geom_point   () +
  geom_line    ( linetype= "dashed", aes(group=subj) ) +
  stat_summary ( geom = "line",  fun    = "mean" ,    linewidth=2, colour="black", linetype="solid") +
  stat_summary ( geom = "point", fun    = "mean" ,    size=2, colour="black") +
  geom_errorbar( stat="summary", fun.data="mean_se",  linewidth=1, fun.args = 2, width = 0.3 ) +
  ylim(0, 25) +
  guides(color = "none")

p2 = ggplot(data.long, aes(x=condition, y=corrected, group=1, colour=subj)) +
  geom_point   () +
  geom_line    ( linetype= "dashed", aes(group=subj) ) +
  stat_summary ( geom = "line",  fun    = "mean" ,    linewidth=2, colour="black", linetype="solid") +
  stat_summary ( geom = "point", fun    = "mean" ,    size=2, colour="black") +
  geom_errorbar( stat="summary", fun.data="mean_se",  linewidth=1, fun.args = 2, width = 0.3 ) +
  ylim(0, 25) +
  guides(color = "none")

grid.arrange(p1, p2, nrow = 1)
```  

   
Then we can use the corrected data to test for normality:
```{r, eval=FALSE}   
by(data = data.long$corrected, INDICES = data.long$condition, FUN = shapiro.test)
par(mfrow=c(1,3))
by(data = data.long$corrected, INDICES = data.long$condition, FUN = hist)
par(mfrow=c(1,1))
```


```{r, eval=TRUE, echo=FALSE}   
by(data = data.long$corrected, INDICES = data.long$condition, FUN = shapiro.test)
```

```{r, echo=FALSE, results='hide', fig.keep='all'}
par(mfrow=c(1,3))
by(data = data.long$corrected, INDICES = data.long$condition, FUN = hist)
par(mfrow=c(1,1))
```



3. Then we check the assumption of spherecity using Mauchly's test (which is built into the ezANOVA)
```{r}
ezModel$`Mauchly's Test for Sphericity`
```
If the assumption of spherecity is violated, you can use the corrected output of the *ezANOVA()* function. You don' need te refer to a non-parametric alternative.

```{r}
ezModel$`Sphericity Corrections`
```
Otherwise we can use the default output as results:
```{r}
ezModel$ANOVA
```
***

#### Using *aov_ez()* (recommended by Jonas) {.active}

  1. First we fit the model using *aov_ez()*
```{r}
library(afex)
afexModel = aov_ez(id = "subj", dv = "score", data = data.long, within = "condition", )
```

  
  2. Next we test the assumption of normality for all the residuals in the model at once:  
```{r, message=FALSE}
hist(afexModel$lm$residuals)
shapiro.test(afexModel$lm$residuals)
```
      
  4. The *aov_ez()* both calculates the ANOVA results and checks for the assumption of sphericity.  
    
  The function also automatically calculates two corrected p-values if the data deviate from sphericity; the Greenhouse-Geisser correction and the Huynh-Feldt correction. If the sphericity test is significant, use one of the corrected p-values (rule of thumb: when the Greenhouse-Geisser Epsilon (GG eps) is less than 0.75, use Greenhouse-Geisser correction [*Pr(>F[GG])*], else use the Huynh-Feldt correction [*Pr(>F(HF))*].  
    
  The degree of the correction depends on the degree of (non)-sphericity. So when the data is perfectly spherical, the correction is zero.
```{r}
summary(afexModel)
```
***  

#### Using *lm()*
fit linear model
```{r}
model = lm(formula = cbind(data.wide$A, data.wide$B, data.wide$C)~1)
```  

  1. Checking assumptions

Test assumption of normality
```{r, results='hide', eval=FALSE}
shapiro.test(model$residuals)
hist(model$residuals)
```

```{r, echo=FALSE}
shapiro.test(model$residuals)
hist(model$residuals)
```

Test assumption of sphericity
```{r}
mauchly.test(model, X=~1)
```

  2. Running the test

Test the model using ANOVA
```{r}
anova(model, X = ~1, test="Spherical")
```

***  

### Non-parametric test

When the assumptions of parametric testing are violated the Friedman ANOVA can be used:
(Note: when the assumption of sphericity is violated you can still run an ANOVA and use the Greenhouse-Geisser corrected F- and p-value.)
```{r}
FMaov = friedman.test(score~condition|subj, data.long)
```


  
  
*** 
## Post-hoc analysis  {.tabset .tabset-pills}

### parametric
For post-hoc analysis the data has to be transformed to the **long format**
<details><summary><span style="color:dodgerBlue">Show code for reshaping </span></summary>
```{r, results='hide'}
# reshape into wide format
data.long = reshape(data = data.wide
                   , direction = 'long'
                   , varying = c("A","B","C")
                   , timevar = 'treatment'
                   , times = c("A","B","C")
                   , v.names = c("score")
                   , idvar = "subj"
                   )
```
</details>
   
      
Use pairwise T-test to compare each combination of conditions
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$treatment          # column name of the first within-subjects variable
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

***  


### Non-parametric
For post-hoc analysis the data has to be transformed to the **long format**
<details><summary><span style="color:dodgerBlue">Show code for reshaping </span></summary>
```{r, results='hide'}
# reshape into wide format
data.long = reshape(data = data.wide
                   , direction = 'long'
                   , varying = c("A","B","C")
                   , timevar = 'treatment'
                   , times = c("A","B","C")
                   , v.names = c("score")
                   , idvar = "subj"
                   )
```
</details> 
   
     
For non-parametric post-hoc test the pairwise Wilcoxon tests can be used as an alternative to the pairwise t-tests. The default method to correct the p-value for multiple comparisons is the *Holm* method (see help file).
```{r}
pairwise.wilcox.test(x = data.long$score, g =data.long$condition, paired = TRUE)
```

   
***  

\newpage

#  Factorial repeated measures ANOVA

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r, echo=TRUE}
set.seed(02)  # set seed
nrofsubs    = 20 # set number of subjects 

data.wide = data.frame(
  ID=1:nrofsubs,
  preA=rnorm(n=nrofsubs, mean = 09,sd = 3),
  preB=rnorm(n=nrofsubs, mean = 10,sd = 3),
  preC=rnorm(n=nrofsubs, mean = 11,sd = 3),
  postA=rnorm(n=nrofsubs, mean = 11,sd = 3),
  postB=rnorm(n=nrofsubs, mean = 15,sd = 3),
  postC=rnorm(n=nrofsubs, mean = 20,sd = 3)
)
rm(list="nrofsubs")

# From wide to long

data.long = pivot_longer(
  data = data.wide, 
  cols = starts_with("pre") | starts_with("post"), 
  names_to = c("time","group"),
  names_pattern = "(pre|post)([A-c])"
)
data.long
```
</details>   


```{r,echo=FALSE}
kable(data.wide[1:4,], row.names = FALSE, caption = 'data.wide') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model

Fit linear model to the data, not yet seperating both independent factors:
```{r}
model = lm(cbind(data.wide$preA,
                 data.wide$preB,
                 data.wide$preC,
                 data.wide$postA,
                 data.wide$postB,
                 data.wide$postC
                 )~1
           )
```
Make a factor matrix clarifying the conditions. Name the colomns as the factors.
Use the parts of the column names of the data.frame in the wide format as variable values in the matrix.
```{r}
factorMatrix = data.frame(
  time=as.factor(rep(c("pre","post"),each=3)),
  condition = as.factor(rep(c("A","B","C"),2))
)
```
fit linear model specifying the two independent variables using the factorMatrix
```{r}
library(car)
factorialAnova = Anova(mod=model, idata=factorMatrix, idesign= ~time*condition, type='III')
```

## Checking assumptions
```{r, eval=FALSE  , results='hide'}
shapiro.test(model$residuals)
hist(model$residuals)
```

```{r, echo=FALSE}
shapiro.test(model$residuals)
hist(model$residuals)
```


## Running the test
run the factorial ANOVA 
```{r}
summary(object = factorialAnova, multivariate=FALSE)
```

The Mauchly Test checks each factor on the assumption of sphericity.
If the Mauchly Test shows a significant result for any of the factors or interaction between factors then a corrected p=value should be used instead of the normal, uncorrected p-value. 

## Post-hoc analysis

For post-hoc analysis the data has to be transformed to the **long format**
<details><summary><span style="color:dodgerBlue">Show code for reshaping </span></summary>
```{r, results='hide'}
# reshape into wide format
data.mix = reshape(data = data.wide
                   , direction = 'long'
                   , varying = list(c('preA','preB','preC'),c('postA','postB','postC'))
                   , timevar = 'treatment'
                   , times = c("A","B","C")
                   , v.names = c("pre","post")
                   , idvar = "ID"
                   )
data.long = reshape(data = data.mix
                   , direction = 'long'
                   , varying = c("pre","post")
                   , timevar = 'pre_post'
                   , times = c("pre","post")
                   , v.names = "score"
                   , idvar = c("ID", "treatment")
                   )
```
</details>

When there are one or more significant main-effects but no significant interaction effect post-hoc comparisons can be made for each factor separately using the pairwise.t.test() function.

Post-hoc comparison for the first factor:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$treatment          # column name of the first within-subjects variable
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

Post-hoc comparison for the first factor:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$pre_post           # column name of the second within-subjects variable
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

When the interaction effect turns out significant, pairwise comparisons can be made between all combinations of conditions.

Post-hoc comparison for the interaction effect:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  # merge both factor columns into a combined factor
  ,g = paste(data.long$treatment, data.long$pre_post)           
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

***  

\newpage

# Mixed-Design ANOVA

<details><summary><span style="color:dodgerBlue">Show code for data generation</span></summary>
```{r, echo=TRUE}
set.seed(02)   # set seed
nrofcondsf1 = 3  # set number of conditions for factor 1
nrofcondsf2 = 2  # set number of conditions for factor 2
nrofsubs    = 30 # set number of subjects per condition
subj = as.factor(rep(x= 1:(nrofsubs*nrofcondsf2), times=nrofcondsf1))       # create array with subject IDs
# create array witht treatment conditions
treatment = as.factor(rep(LETTERS[1:nrofcondsf1],each=nrofsubs*nrofcondsf2))   
# create array with control / experimental
gender   = as.factor(rep(c("men","women"),times=nrofsubs*nrofcondsf1))   
# create array with measurement values
score = as.vector( replicate(nrofcondsf1, replicate ( 
          nrofcondsf2 , rnorm(
            n = (nrofsubs), 
            mean = 0 , sd = sample(5,1) ) + sample(8,1)+10
        ) ) )                             
# combine arrays into a data.frame
data.long = data.frame(subj, score, treatment, gender);      
# delete unnecessary arrays
rm(list=c("gender","nrofcondsf1","nrofcondsf2","nrofsubs","score","subj","treatment"))

```   
</details>     

```{r,echo=FALSE}
kable(data.long[c(1:2,61:62,121:122),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model

Fit mixed-model using ezANOVA() function
```{r}
mix.model = ezANOVA(data = data.long      # name of the data frame (long format)
                    , dv = score          # column name of the dependent variabele
                    , wid = subj          # column name indicating subject ID
                    , within = treatment  # column name of the within factor
                    , between = gender    # column name of the between factor
                    , return_aov = TRUE   # add information to the output for normality testing
                    )
```

## Checking assumptions

Test assumption of normality of the residuals
```{r, echo=TRUE, eval=FALSE, results='hide'}
shapiro.test(mix.model$aov$`subj:treatment`$residuals)

hist(mix.model$aov$`subj:treatment`$residuals
     , xlab = 'Residuals'
     , main = 'Histogram of residuals')
```
```{r, echo=FALSE, eval=TRUE}
shapiro.test(mix.model$aov$`subj:treatment`$residuals)
hist(mix.model$aov$`subj:treatment`$residuals, xlab = 'Residuals', main = 'Histogram of residuals')
```

Test assumption of sphericity
```{r}
mix.model$`Mauchly's Test for Sphericity`
```

## Running the test
If the assumption of sphericity is met use the normal, uncorrected ANOVA output
```{r}
mix.model$ANOVA
```

If the assumption of sphericity is violated, use the corrected ANOVA output
(The Greenhouse-Geisser correction is more conservative than the Huynd-Feldt correction)
```{r}
mix.model$`Sphericity Corrections`
```

## Post-hoc analysis

When there are one or more significant main-effects but no significant interaction effect post-hoc comparisons can be made using the pairwise.t.test() function.

Post-hoc comparison for the between-subjects factor:
```{r}
pairwise.t.test(
  x=data.long$score               # column name of the dependent variable
, g=data.long$gender              # column name of the independent between-subjects variable
, paired = TRUE                   # for the within factor, set paired=TRUE
, p.adjust.method = 'bonferroni'  # use bonferroni corrected p-values
)
```

Post-hoc comparison for the within-subjects factor:
```{r}
pairwise.t.test(
  x=data.long$score               # column name of the dependent variable
, g=data.long$treatment           # column name of the independent within-subjects variable
, paired = TRUE                   # for the within factor, set paired=TRUE
, p.adjust.method = 'bonferroni'  # use bonferroni corrected p-values
)
```

When the interaction-effect turns out significant, pairwise comparisons within each factor are not very informative about what the interaction looks like. Pairwise comparisons between all combinations of conditions is inappropriate when dealing with mixed designs. The best way to interpret an interaction effect is by looking at the interaction pattern in the data using descriptive statistics and visualization.

