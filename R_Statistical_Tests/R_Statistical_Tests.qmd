---
title: "Overview statistic tests PB"  
author: "Jonas van Nijnatten"


format: 
  html: 
    page-layout: full
    grid:
      body-width: 1000px
      margin-width: 250px
      sidebar-width: 250px
    fig-width: 12
    embed-resources: true
    lightbox: true
    toc: true
    toc-depth: 4
    toc-float: true
    toc-location: right

    number-sections: true
    margin-left: 5px
    margin-right: 80px

  # pdf:
  #   fig_caption: true
  #   number_sections: true
  #   toc: true
  #   toc_depth: '2'
    
execute: 
  image-width: 1200px
  cache: true
knitr: 
  opts_chunk: 
    message: false
    warning: false 
    fig-show: hold
    results: hold    
    
pdf-engine-opts:
  - '-latex-auto-install= true'
 
# header-includes:
# - \usepackage{geometry}
# - \geometry{a4paper, portrait, margin=.75in}
---



```{css, echo=FALSE, eval=FALSE}
<!-- body .main-container{ -->
<!--   max-width: 2500px; -->
<!--   width: 100%; -->
<!--   margin: 0; -->
<!--  padding: 1em; -->
<!--  line-height: 20px ;  -->
<!-- }    -->

<!-- body { -->
<!--   max-width: 2500px; -->
<!--   width: 100%; -->
<!--   margin: 0; -->
<!--  padding: 1em; -->
<!--  line-height: 20px ;  -->
<!-- }    -->

<!-- #TOC { -->
<!--   max-width: 280px; -->
<!--   width: 20%; -->
<!-- } -->
```
contact: <J.J.vanNijnatten@uva.nl>

source code: <https://github.com/jonasvannijnatten/PB_statistiek>

laatste update: `r format.Date(Sys.Date(), '%d-%m-%Y')`

Other R manuals for Psychobiology: <https://jonasvannijnatten.github.io/PB_statistiek/>  
  
***

\newpage

#   R and package versions
## Versions  
software versions used for this tutorial:  
 - `r R.Version()$version.string`   
 - car-package version: `r packageVersion("car")` (`r packageDate("car")`)  
 - lmerTest-package version: `r packageVersion("lmerTest")` (`r packageDate("lmerTest")`)
 - ez-package version:  `r packageVersion("ez")` (`r packageDate("ez")`)
 
##  Installation
Install & activate the required packages:
```{r}
#| label: "package installation"
#| echo: false
#| results: hide
#| message: false
#| warning: false
reqPacks = c("markdown","knitr","kableExtra","car","ez","afex", "ggplot2", "gridExtra","lmerTest","interactions","tidyverse", "performance","emmeans")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(reqPacks, character.only = TRUE)
```

```{r}
#| label: "print packages"
#| echo: false
cat(reqPacks, sep="\n")
```

***

\newpage

#  T-test

## Independent samples T-test
<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r}
#| label: "indep Test data"
# generate data
N = 40
data.long = data.frame(
  ID = 1:N,
  condition = rep(x = c("A","B"), each = N),
  score = c(rnorm(n = N, mean = 25, sd = 6.5), rnorm(n = N, mean = 35, sd = 6.5))
)
```
</details>

```{r}
#| label: "show table"
#| echo: false
kable(data.long[c(1:5,41:45),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

Test assumption of normality
```{r}
by(data = data.long$score, INDICES = data.long$condition, FUN = shapiro.test)
```
Test assumption of equality of variances
```{r}
leveneTest(y = data.long$score, group = data.long$condition)
```
**T-test**
```{r}
summary(lm(formula = score ~ condition, data = data.long))
t.test(formula = score ~ condition, data = data.long, alternative="two.sided", var.equal=TRUE)
```

## Paired samples T-test
<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r}
# generate data
N = 30
data.long = data.frame(
  ID = rep(1:N,2),
  condition = rep(x = c("A","B"), each = N),
  score = c(rnorm(n = N, mean = 25, sd = 6.5), rnorm(n = N, mean = 35, sd = 6.5))
)
```
</details>

```{r,echo=FALSE}
kable(data.long[c(1:5,31:35),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

Test assumption of normality
```{r}
# calculate difference scores
diffScore = data.long$score[data.long$condition=="A"] - data.long$score[data.long$condition=="B"]
shapiro.test(diffScore)
```

**T-test**
```{r}
t.test(formula = score ~ 1, data = data.long, alternative="two.sided", var.equal=TRUE)
lmer(formula = score ~ condition+(1|ID), data = data.long)
```

***
\newpage

#  Correlation

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary> 
```{r}
# generate data
set.seed(05)
nrobs = 100
experience = rnorm(n = nrobs, mean = 15, sd = 3)
salary     = 10000 + ( 5 * experience ) + rnorm(n = nrobs, mean = 0, sd = 100)
data.long = data.frame(experience, salary)
# calculate correlation coefficient r
corr_coef = cor(x = data.long$experience, y = data.long$salary)
rm(list = c("nrobs", "experience", "salary"))
```
</details>   

```{r,echo=FALSE}
kable(data.long[1:5,], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```
Test assumption of normality
```{r}
apply(X = data.long, MARGIN = 2, FUN = shapiro.test)
```

**Pearson correlation**
```{r}
cor.test(x=data.long$experience, y=data.long$salary, alternative = "two.sided", method = "pearson")
```

**Spearman correlation**
```{r}
cor.test(x=data.long$experience, y=data.long$salary, alternative = "two.sided", method = "spearman")
```
 ***
 
\newpage 

# Regression

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary> 
```{r}
#| label: "simple regression data"
# generate data
set.seed(05)
nrobs = 100
experience = rnorm(n = nrobs, mean = 15, sd = 3)
salary     = 10000 + ( 5 * experience ) + rnorm(n = nrobs, mean = 0, sd = 100)
data.long = data.frame(experience, salary)
# calculate correlation coefficient r
corr_coef = cor(x = data.long$experience, y = data.long$salary)
rm(list = c("nrobs", "experience", "salary"))
```
</details>   

```{r}
#| label: "show data table"
#| echo: false
kable(data.long[1:5,], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

Fit linear model
```{r}
#| label: "simple regression model fit"
linearModel = lm(formula = salary ~ experience, data = data.long)
```

Test assumption of normality & equal variances
```{r}
#| label: "simple regression assumption checks"
check_model(linearModel)
```
**Regression test**
```{r}
#| label: "simple regression output"
summary(linearModel)
```


***  
\newpage

# Logistic regression

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary> 
```{r}
#| label: "logistic regression data"
set.seed(01)
N = 30
x = sort(runif(n = N, min = 0, max = 10))
y = round(
  1 / (1 + exp(-.5*x+(max(x)/4) + rnorm(N,0,1.5)))  # logistic function of x + noise
  ) # round it to either 1 or 0
data.long = data.frame(x = x, y = y)
```
</details>

```{r}
#| label: "logistic regression model fitting"
# fit a logistic model, which is a generalized linear model, hence glm() function
glm.fit <- glm(y ~ x, data = data.long, family = binomial('logit'))
# test the logistic model against the NULL model
summary(glm.fit)
```
```{r}
#| label: "Logistic regression plot"
ggplot(data.long, aes(x=x, y=y)) + geom_point() +
  stat_smooth(method="glm", color="blue", se=TRUE, 
              method.args = list(family=binomial)) +
  theme_classic()
```

***  
\newpage

#  One-way independent samples ANOVA
<details><summary><span style="color:dodgerBlue">Toon code om voorbeeld data te genereren </span></summary>
```{r}
#| label: "ANOVA data"
set.seed(05)   # set seed
nrofconds = 3  # set number of conditions
nrofsubs  = 20 # set number of subjects
subj = as.factor(1:(nrofsubs*nrofconds))      # create array with subject IDs
condition = as.factor(rep(LETTERS[1:nrofconds],each=nrofsubs))   # create array with condition values
score = as.vector( replicate(
          nrofconds , rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1) ) 
        ) )                                     # create array with measurement values
data.long = data.frame(subj, condition, score);      # combine arrays into a data.frame
rm(list=c("subj", "condition","score","nrofconds","nrofsubs")) # delete unnecessary variables

```   
</details>  
   
```{r}
#| label: "show data"
#| echo: false
kable(data.long[c(1:2,21:22,41:42),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```


## Running the test {.tabset .tabset-pills}

:::{.panel-tabset}
### parametric methods {.tabset .tabset-pills}

::::{.panel-tabset}
#### using *lm()* (PB recommended) {.active}  

***ANOVA*** using the linear model method

Fit the model using *lm()*.
```{r}
#| label: "lm fit"
#| message: false
lmModel = lm(formula = score ~ condition, data = data.long)
```

Check the assumptions using *performance::check_model()*
```{r}
#| label: "assumptions check"
check_model(lmModel)
```

To get the results of the hypothesis test, use the anova() function
```{r}
#| label: "hypothesis test"
anova(lmModel)
```

Post-hoc testing
When using the linear model method, use pairwise t-test or emmeans() from the emmeans package.
```{r}
#| label: "post hoc testing"
pairwise.t.test(x = data.long$score, g = data.long$condition, paired = FALSE, p.adjust.method = "bonferroni")

# for post hoc comparison of conditions using the emmeans() function from the emmeans package
emmeans(lmModel, pairwise~condition, )
```


#### using *ezANOVA()*
***ANOVA*** using the ezANOVA method

Test assumption of normality
```{r}
by(data = data.long$score, INDICES = data.long$condition, FUN = shapiro.test)
```
Test equality of variances
```{r}
leveneTest(y = data.long$score, group = data.long$condition)
```

```{r, message=FALSE}
ezModel = ezANOVA(data = data.long, dv = score, between = condition, wid = subj)
ezModel$ANOVA
```



#### using *aov_ez()*
***ANOVA*** using the aov_ez() method
1. First we build the model using the *aov_ez()* function from the *afex* package.  
```{r, message=FALSE}
afexModel = aov_ez(data = data.long, id = "subj", dv = "score", between = "condition")
afexModel$anova_table
``` 
  

2. Next we test the assumption of normality for all the residuals in the model at once:
```{r, message=FALSE}
hist(afexModel$lm$residuals)
shapiro.test(afexModel$lm$residuals)
```

```{r, results='hide', fig.keep='all'}
# library(car)
qqPlot(afexModel$lm)
```  
  
3. Then we test the assumption of equal variences using Levene's Test:
```{r}
leveneTest(afexModel$lm)
```



#### using *aov()*
***ANOVA*** using the aov method


Test assumption of normality
```{r}
by(data = data.long$score, INDICES = data.long$condition, FUN = shapiro.test)
```
Test equality of variances
```{r}
leveneTest(y = data.long$score, group = data.long$condition)
```

Run the ANOVA and check the results
```{r, message=FALSE}
aovModel = aov(formula = score ~ condition, data = data.long)
summary(aovModel)
```

When using the aov method, use the Tukey post-hoc test
```{r}
TukeyHSD(aovModel)
```

::::



### Non-parametric methods
```{r}
#| label: "Kruskal-Wallis"
#| message: false
kruskal.test(score~condition, data.long)
```

:::


***  
\newpage

#  Factorial independent samples ANOVA

<details><summary><span style="color:dodgerBlue">Show code for data generation</span></summary>
```{r, echo=TRUE}
#| label: "Factorial independent samples ANOVA"
set.seed(01)   # set seed
nrofcondsf1 = 3  # set number of conditions for factor 1
nrofcondsf2 = 2  # set number of conditions for factor 2
nrofsubs    = nrofcondsf1*nrofcondsf2*30 # set number of subjects per condition
subj = as.factor(1:(nrofsubs))      # create array with subject IDs
# create array witht treatment conditions
treatment = as.factor(rep(LETTERS[1:nrofcondsf1],each=nrofsubs/nrofcondsf1))   
# create array with control / experimental
control   = as.factor(rep(c("control","experimental"),times=nrofsubs/nrofcondsf2))   
# create array with measurement values
score = as.vector( replicate(nrofcondsf1, replicate ( 
          nrofcondsf2 , rnorm(
            n = (nrofsubs/(nrofcondsf1*nrofcondsf2)), 
            mean = 0 , sd = sample(5,1) ) + sample(8,1)+10
        ) ) )                             
# combine arrays into a data.frame
data.long = data.frame(subj, score, treatment, control);      
# delete unnecessary arrays
rm(list=c("control","nrofcondsf1","nrofcondsf2","nrofsubs","score","subj","treatment"))

```   
</details>     

```{r,echo=FALSE}
kable(data.long[c(1:2,61:62,121:122),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model

Fit model with multiple prediction factors
```{r}
model = lm(formula = score ~ treatment+control, data = data.long)
```

## Checking assumptions

Visually inspect all assumptions using the *check_model()* function from the *performance* package.

```{r}
#| label: "check assumptions"
check_model(model)
```




<!-- Test assumption of normality -->
<!-- ```{r, eval=FALSE} -->
<!-- hist(model$residuals) -->
<!-- plot(x = fitted(model), y = residuals(model), xlab="predicted", ylab="residuals"); abline(h=0) -->
<!-- by(data = data.long$score, INDICES = paste(data.long$treatment, data.long$control), FUN = shapiro.test) -->
<!-- ``` -->
<!-- <details><summary><span style="color:dodgerBlue">Show residuals histogram</span></summary> -->
<!-- ```{r, echo=FALSE} -->
<!-- hist(model$residuals) -->
<!-- ``` -->
<!-- </details> -->
<!-- <details><summary><span style="color:dodgerBlue">Show residuals vs predicted plot</span></summary> -->
<!-- ```{r, echo=FALSE} -->
<!-- plot(x = fitted(model), y = residuals(model), xlab="predicted", ylab="residuals"); abline(h=0) -->
<!-- ``` -->
<!-- </details> -->
<!-- <details><summary><span style="color:dodgerBlue">Show output of Shapiro-Wilk test</span></summary> -->
<!-- ```{r, echo=FALSE} -->
<!-- by(data = data.long$score, INDICES = paste(data.long$treatment, data.long$control), FUN = shapiro.test) -->
<!-- ``` -->
<!-- </details> -->

<!-- Test equality of variances -->
<!-- ```{r} -->
<!-- leveneTest(y = data.long$score, group = as.factor(paste(data.long$treatment, data.long$control))) -->
<!-- ``` -->

## Running the test

ANOVA with the linear model method
```{r}
model = lm(formula = score ~ treatment*control, data = data.long)
library(car)
Anova(mod = model, type = 'II')
summary(model)
```
\newpage 

## Post-hoc analysis

:::{.panel-tabset}

### Using the estimated marginal means (emmeans)

When there are one or more significant main-effects but no significant interaction effect post-hoc comparisons can be made for each factor separately using the emmeans() function.  

#### Post-hoc inspection of the main effect of the factor *treatment*.
```{r}
#| label: "Factorial ANOVA post-hoc with emmeans treatment"
emmeans(model, pairwise ~ treatment)
```

#### Post-hoc inspection of the main effect of the factor *control*.
```{r}
#| label: "Factorial ANOVA post-hoc with emmeans control"
emmeans(model, pairwise ~ control)
```

#### Post-hoc inspection of the interaction effect
```{r}
#| label: "Factorial ANOVA post-hoc with emmeans interaction"
emmeans(model, pairwise ~ treatment + control)
```

### Using pairwise T-tests

When there are one or more significant main-effects but no significant interaction effect post-hoc comparisons can be made for each factor separately using the pairwise.t.test() function.

#### Post-hoc comparison for the first factor
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$treatment          # column name of the first within-subjects variable
  , paired = FALSE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

#### Post-hoc comparison for the second factor
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$control           # column name of the second within-subjects variable
  , paired = FALSE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

#### Post-hoc comparison for the interaction effect
When the interaction effect turns out significant, pairwise comparisons can be made between all combinations of conditions.
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  # merge both factor columns into a combined factor
  ,g = paste(data.long$treatment, data.long$control)           
  , paired = FALSE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```
::: 



***  
\newpage  

#  One-way repeated measures ANOVA
<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r, echo=TRUE}
# Generate dataset
set.seed(01)   # set seed
nrofsubs  = 20 # set number of subjects
data.wide = data.frame(
  subj = as.factor(1:nrofsubs)   ,
  A =  rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1)) ,
  B =  rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1)) ,
  C =  rnorm(n = nrofsubs, mean = sample(8,1)+10 , sd = sample(5,1))
)
rm(list=c("nrofsubs")) # delete arrays

# reshape the data to the long format for some analysis methods
data.long = reshape(
  data = data.wide
  ,direction  = 'long'          # richting van de data-transformatie
  ,varying    = c('A','B','C')  # kolomnamen die worden samengevoegd
  ,idvar      = 'subj'          # kolomnaam met de ppn-nummers
  ,v.names    = 'score'         # naam van nieuwe kolom met meetwaarden
  ,timevar    = 'condition'     # naam van nieuwe kolom met condities
  ,times      = c('A','B','C')  # waardes 
  )
data.long$condition = as.factor(data.long$condition)
```
</details>  

```{r,echo=FALSE}
kable(data.wide[1:4,], row.names = FALSE, caption = 'data.wide') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")

kable(data.long[c(1:2,21:22,41:42),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model 

:::{.panel-tabset}

### Parametric Test  

::::{.panel-tabset}

#### Using *lmer()* from *lmerTest* package {.active}
First we fit the model using the *lmer()* function:
```{r}
#| label: "RM ANOVA lmer"
model = lmer(
  formula = score~condition+(1|subj), 
  data = data.long
  )
```

Visually inspect the assumptions using the *check_model()* function.
```{r}
#| label: "RM ANOVA check assumptions"
check_model(model)
```
Get the inferential statistics of the model fit
```{r}
#| label: "RM ANOVA lemr inferential statistics"
anova(model)
```


#### Using *ezAONVA*

1. First we fit the model using the *ezANOVA()* function:
```{r}
ezModel = ezANOVA(data = data.long, dv = score, wid = subj, within = condition)
```
  
2. Then we check for the assumption of normality. Because the model takes into account individual differences, we should first correct the individual score by removing the individual differences from the data.
We do this by calculating how each individual differes from the overall mean.

$corrected = Y_{i,j}corrected - (\overline{Yi} - \overline{Y})$  

where $i$ represents the individual subjects, and $j$ represents the different conditions

```{r, results='hold', warning=TRUE, fig.ncol=2}
# initialize variables to store calculate correted score
data.long$subjMean     = rep(NA, dim(data.long)[1])
data.long$correction   = rep(NA, dim(data.long)[1])
data.long$corrected    = rep(NA, dim(data.long)[1])

for (i in unique(data.long$subj)){
  # calculate the mean score for each subject (across conditions)
  data.long$subjMean[which(data.long$subj==i)] = mean(data.long$score[which(data.long$subj==i)])
  # calculate the correction as the difference between the subject mean vs the overall mean
  data.long$correction[which(data.long$subj==i)] = 
    (data.long$subjMean[which(data.long$subj==i)] - mean(data.long$score))
  # calculate the corrected score by subtracting the correction per subject from each individual score value
  data.long$corrected[which(data.long$subj==i)] = 
    data.long$score[which(data.long$subj==i)] - data.long$correction[which(data.long$subj==i)]
}


p1 = ggplot(data.long, aes(x=condition, y=score, group=1, colour=subj)) +
  geom_point   () +
  geom_line    ( linetype= "dashed", aes(group=subj) ) +
  stat_summary ( geom = "line",  fun    = "mean" ,    linewidth=2, colour="black", linetype="solid") +
  stat_summary ( geom = "point", fun    = "mean" ,    size=2, colour="black") +
  geom_errorbar( stat="summary", fun.data="mean_se",  linewidth=1, fun.args = 2, width = 0.3 ) +
  ylim(0, 25) +
  guides(color = "none")

p2 = ggplot(data.long, aes(x=condition, y=corrected, group=1, colour=subj)) +
  geom_point   () +
  geom_line    ( linetype= "dashed", aes(group=subj) ) +
  stat_summary ( geom = "line",  fun    = "mean" ,    linewidth=2, colour="black", linetype="solid") +
  stat_summary ( geom = "point", fun    = "mean" ,    size=2, colour="black") +
  geom_errorbar( stat="summary", fun.data="mean_se",  linewidth=1, fun.args = 2, width = 0.3 ) +
  ylim(0, 25) +
  guides(color = "none")

grid.arrange(p1, p2, nrow = 1)
```  

   
Then we can use the corrected data to test for normality:
```{r, eval=FALSE}   
by(data = data.long$corrected, INDICES = data.long$condition, FUN = shapiro.test)
par(mfrow=c(1,3))
by(data = data.long$corrected, INDICES = data.long$condition, FUN = hist)
par(mfrow=c(1,1))
```


```{r, eval=TRUE, echo=FALSE}   
by(data = data.long$corrected, INDICES = data.long$condition, FUN = shapiro.test)
```

```{r, echo=FALSE, results='hide', fig.keep='all'}
par(mfrow=c(1,3))
by(data = data.long$corrected, INDICES = data.long$condition, FUN = hist)
par(mfrow=c(1,1))
```



3. Then we check the assumption of spherecity using Mauchly's test (which is built into the ezANOVA)
```{r}
ezModel$`Mauchly's Test for Sphericity`
```
If the assumption of spherecity is violated, you can use the corrected output of the *ezANOVA()* function. You don' need te refer to a non-parametric alternative.

```{r}
ezModel$`Sphericity Corrections`
```
Otherwise we can use the default output as results:
```{r}
ezModel$ANOVA
```
***

#### Using *aov_ez()*

  1. First we fit the model using *aov_ez()*
```{r}
library(afex)
afexModel = aov_ez(id = "subj", dv = "score", data = data.long, within = "condition", )
```

  
  2. Next we test the assumption of normality for all the residuals in the model at once:  
```{r, message=FALSE}
hist(afexModel$lm$residuals)
shapiro.test(afexModel$lm$residuals)
```
      
  4. The *aov_ez()* both calculates the ANOVA results and checks for the assumption of sphericity.  
    
  The function also automatically calculates two corrected p-values if the data deviate from sphericity; the Greenhouse-Geisser correction and the Huynh-Feldt correction. If the sphericity test is significant, use one of the corrected p-values (rule of thumb: when the Greenhouse-Geisser Epsilon (GG eps) is less than 0.75, use Greenhouse-Geisser correction [*Pr(>F[GG])*], else use the Huynh-Feldt correction [*Pr(>F(HF))*].  
    
  The degree of the correction depends on the degree of (non)-sphericity. So when the data is perfectly spherical, the correction is zero.
```{r}
summary(afexModel)
```
***  

<!-- #### Using *lm()* -->
<!-- fit linear model -->
<!-- ```{r} -->
<!-- model = lm(formula = cbind(data.wide$A, data.wide$B, data.wide$C)~1) -->
<!-- ```   -->

<!--   1. Checking assumptions -->

<!-- Test assumption of normality -->
<!-- ```{r, results='hide', eval=FALSE} -->
<!-- shapiro.test(model$residuals) -->
<!-- hist(model$residuals) -->
<!-- ``` -->

<!-- ```{r, echo=FALSE} -->
<!-- shapiro.test(model$residuals) -->
<!-- hist(model$residuals) -->
<!-- ``` -->

<!-- Test assumption of sphericity -->
<!-- ```{r} -->
<!-- mauchly.test(model, X=~1) -->
<!-- ``` -->

<!--   2. Running the test -->

<!-- Test the model using ANOVA -->
<!-- ```{r} -->
<!-- anova(model, X = ~1, test="Spherical") -->
<!-- ``` -->

***  
::::

### Non-parametric test

When the assumptions of parametric testing are violated the Friedman ANOVA can be used:
(Note: when the assumption of sphericity is violated you can still run an ANOVA and use the Greenhouse-Geisser corrected F- and p-value.)
```{r}
FMaov = friedman.test(score~condition|subj, data.long)
```

:::
  
  
*** 

## Post-hoc analysis

:::{.panel-tabset}
### parametric
For post-hoc analysis the data has to be transformed to the **long format**
<details><summary><span style="color:dodgerBlue">Show code for reshaping </span></summary>
```{r, results='hide'}
# reshape into wide format
data.long = reshape(data = data.wide
                   , direction = 'long'
                   , varying = c("A","B","C")
                   , timevar = 'treatment'
                   , times = c("A","B","C")
                   , v.names = c("score")
                   , idvar = "subj"
                   )
```
</details>

::::{.panel-tabset}
#### Using emmeans
Use the estimated marginal means (emmeans) for post-hoc analysis.
```{r}
#| label: "RM ANOVA emmeans post-hoc"
ref.grid = ref_grid(model)
condition.emm = emmeans(ref.grid, "condition")
pairs(condition.emm, reverse = FALSE)
```



#### Using pairwise T-test
Use pairwise T-test to compare each combination of conditions
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$treatment          # column name of the first within-subjects variable
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```
::::
***  


### Non-parametric
For post-hoc analysis the data has to be transformed to the **long format**
<details><summary><span style="color:dodgerBlue">Show code for reshaping </span></summary>
```{r, results='hide'}
# reshape into wide format
data.long = reshape(data = data.wide
                   , direction = 'long'
                   , varying = c("A","B","C")
                   , timevar = 'treatment'
                   , times = c("A","B","C")
                   , v.names = c("score")
                   , idvar = "subj"
                   )
```
</details> 
   
     
For non-parametric post-hoc test the pairwise Wilcoxon tests can be used as an alternative to the pairwise t-tests. The default method to correct the p-value for multiple comparisons is the *Holm* method (see help file).
```{r}
pairwise.wilcox.test(x = data.long$score, g =data.long$condition, paired = TRUE)
```
:::
   
***  

\newpage

#  Factorial repeated measures ANOVA

<details><summary><span style="color:dodgerBlue">Show code for data generation </span></summary>
```{r, echo=TRUE}
set.seed(02)  # set seed
nrofsubs    = 20 # set number of subjects 

data.wide = data.frame(
  ID=1:nrofsubs,
  preA=rnorm(n=nrofsubs, mean = 09,sd = 3),
  preB=rnorm(n=nrofsubs, mean = 10,sd = 3),
  preC=rnorm(n=nrofsubs, mean = 11,sd = 3),
  postA=rnorm(n=nrofsubs, mean = 11,sd = 3),
  postB=rnorm(n=nrofsubs, mean = 15,sd = 3),
  postC=rnorm(n=nrofsubs, mean = 20,sd = 3)
)
rm(list="nrofsubs")

# From wide to long

data.long = pivot_longer(
  data = data.wide, 
  cols = starts_with("pre") | starts_with("post"), 
  names_to = c("time","group"),
  names_pattern = "(pre|post)([A-c])", 
  values_to = "score"
)
data.long
```
</details>   


```{r,echo=FALSE}
kable(data.wide[1:4,], row.names = FALSE, caption = 'data.wide') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")

kable(data.long[c(1,2,7,8,13,14,19,20,25,26),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

## Fitting the model

Fit the model using *lmer()* from the *lmerTest* package.
```{r}
model = lmerTest::lmer(score~time*group+(1|ID), data.long)
```

## Checking assumptions 
Use *check_model()* from the *preformance* package.
```{r}
check_model(model)
```



<!-- Fit linear model to the data, not yet seperating both independent factors: -->
<!-- ```{r} -->
<!-- model = lm(cbind(data.wide$preA, -->
<!--                  data.wide$preB, -->
<!--                  data.wide$preC, -->
<!--                  data.wide$postA, -->
<!--                  data.wide$postB, -->
<!--                  data.wide$postC -->
<!--                  )~1 -->
<!--            ) -->
<!-- ``` -->
<!-- Make a factor matrix clarifying the conditions. Name the colomns as the factors. -->
<!-- Use the parts of the column names of the data.frame in the wide format as variable values in the matrix. -->
<!-- ```{r} -->
<!-- factorMatrix = data.frame( -->
<!--   time=as.factor(rep(c("pre","post"),each=3)), -->
<!--   condition = as.factor(rep(c("A","B","C"),2)) -->
<!-- ) -->
<!-- ``` -->
<!-- fit linear model specifying the two independent variables using the factorMatrix -->
<!-- ```{r} -->
<!-- library(car) -->
<!-- factorialAnova = Anova(mod=model, idata=factorMatrix, idesign= ~time*condition, type='III') -->
<!-- ``` -->

<!-- ## Checking assumptions -->
<!-- ```{r, eval=FALSE  , results='hide'} -->
<!-- shapiro.test(model$residuals) -->
<!-- hist(model$residuals) -->
<!-- ``` -->

<!-- ```{r, echo=FALSE} -->
<!-- shapiro.test(model$residuals) -->
<!-- hist(model$residuals) -->
<!-- ``` -->


## Running the test
Get the inferential statistics using *anova()*
```{r}
#| label: "Factorial RM ANOVA inferential"
anova(model)
```


<!-- run the factorial ANOVA  -->
<!-- ```{r} -->
<!-- summary(object = factorialAnova, multivariate=FALSE) -->
<!-- ``` -->

<!-- The Mauchly Test checks each factor on the assumption of sphericity. -->
<!-- If the Mauchly Test shows a significant result for any of the factors or interaction between factors then a corrected p=value should be used instead of the normal, uncorrected p-value.  -->

## Post-hoc analysis

:::{.panel-tabset}
### Emmeans
When there are one or more significant main-effects but no significant interaction effect, post-hoc comparisons can be made for each factor separately.

#### Post-hoc comparison for the first factor
Use the *emmeans()* function, providing the model as first input argument.
The second input argument is a formula telling the function to do a pairwise comparison of the different levels of the factor "group" (levels: A, B and C).
The resulting output gives:  
1) the estimated means per group level  
2) the pairwise differences and corresponding t-value, degrees of freedom and p-value.
```{r}
emmeans(object = model, specs = pairwise ~ group)
```

#### Post-hoc comparison for the second factor:
```{r}
emmeans(object = model, specs = pairwise ~ time)
```

#### Post-hoc comparison for interaction
When the interaction effect turns out significant, pairwise comparisons can be made between combinations of the factors. One option is a pairwise comparison of all combinations. This is done by using the fomrula "pairwise ~ group * time" as the second input argument.
```{r}
emmeans(model, pairwise ~ group*time)
```

However, usually not all comparisons are equally interesting/useful.
So another option is to compare between levels of factor 1, within different levels of factor 2. 
This can be done by providing a simple formula for the first factor ("pairwise ~ time") and adding a third input argument *by* for the second factor (in this example "group").
```{r}
#| label: "Facorial RM ANOVA post-hoc emmeans"
emmeans(object = model, specs = pairwise~time, by="group")
```
This compares the "pre" and "post" levels within each level of "group" (A, B and C).
The other way around we can also compare the three levels of "group" within each other per level of "time" using the following code: (Note: by adding $contrasts after the function call we only get the statistical comparisons, and not the means per condition, as they are the same as in the previous call)
```{r}
emmeans(object = model, specs = pairwise~group, by="time")$contrasts
```

### Pairwise T-tests
When there are one or more significant main-effects but no significant interaction effect, post-hoc comparisons can be made for each factor separately using the pairwise.t.test() function.

Post-hoc comparison for the first factor:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$treatment          # column name of the first within-subjects variable
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

Post-hoc comparison for the first factor:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  ,g = data.long$pre_post           # column name of the second within-subjects variable
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

When the interaction effect turns out significant, pairwise comparisons can be made between all combinations of conditions.

Post-hoc comparison for the interaction effect:
```{r}
pairwise.t.test(
  x = data.long$score               # column name of the dependent variable
  # merge both factor columns into a combined factor
  ,g = paste(data.long$treatment, data.long$pre_post)           
  , paired = TRUE                   # since it is a paired design, set paired=TRUE
  , p.adjust.method = "bonferroni"  # use bonferroni corrected p-values
  )
```

:::


## Visualisation
```{r}
cat_plot(model = model, 
         pred = time, 
         modx = group, 
         interval = TRUE, 
         plot.points = TRUE, 
         jitter = 0.2)
```

***  

\newpage

# Mixed-Design ANOVA

<details><summary><span style="color:dodgerBlue">Show code for data generation</span></summary>
```{r, echo=TRUE}
set.seed(02)   # set seed
nrofcondsf1 = 3  # set number of conditions for factor 1
nrofcondsf2 = 2  # set number of conditions for factor 2
nrofsubs    = 30 # set number of subjects per condition
subj = as.factor(rep(x= 1:(nrofsubs*nrofcondsf2), times=nrofcondsf1))       # create array with subject IDs
# create array witht treatment conditions
treatment = as.factor(rep(LETTERS[1:nrofcondsf1],each=nrofsubs*nrofcondsf2))   
# create array with control / experimental
gender   = as.factor(rep(c("men","women"),times=nrofsubs*nrofcondsf1))   
# create array with measurement values
score = as.vector( replicate(nrofcondsf1, replicate ( 
          nrofcondsf2 , rnorm(
            n = (nrofsubs), 
            mean = 0 , sd = sample(3,1)+2 ) + sample(8,1)+10
        ) ) )                             
# combine arrays into a data.frame
data.long = data.frame(subj, score, treatment, gender);      
# delete unnecessary arrays
# rm(list=c("gender","nrofcondsf1","nrofcondsf2","nrofsubs","score","subj","treatment"))

```   
</details>     

```{r,echo=FALSE}
kable(data.long[c(1:2,61:62,121:122),], row.names = FALSE, caption = 'data.long') %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE, position = "left")
```

:::{.panel-tabset}
## Using *lmer()* (PB recommended) {.active}

### Fitting the model
Here we use the same code as with a factorial repeated measures ANOVA to fit the model:
```{r}
model = lmerTest::lmer(
  formula = score~treatment*gender + (1|subj), 
  data = data.long)
```

### Checking assumptions
Then we can inspect the assumptions of the model:
```{r}
check_model(model)
```
### Running the test
Then we can get the inferential statistics on both main effects and the interaction effect.
```{r}
anova(model)
```
### Post-hoc analysis
When there are significant main effects but no significant interaction effect we can inspect the post-hoc comparisons within each factor:
```{r}

emmeans(object = model, specs = pairwise~treatment)

emmeans(object = model, specs = pairwise~gender)
```

When there is a significant interaction effect it is more relevant to inspect the combinations of factors: 
```{r}
emmeans(object=model, specs=pairwise~treatment, by="gender")
emmeans(object=model, specs=pairwise~gender, by="treatment")$contrasts
```




## Using *ezANOVA()*
Fit mixed-model using ezANOVA() function
```{r}
mix.model = ezANOVA(data = data.long      # name of the data frame (long format)
                    , dv = score          # column name of the dependent variabele
                    , wid = subj          # column name indicating subject ID
                    , within = treatment  # column name of the within factor
                    , between = gender    # column name of the between factor
                    , return_aov = TRUE   # add information to the output for normality testing
                    )
```

### Checking assumptions

Test assumption of normality of the residuals
```{r, echo=TRUE, eval=FALSE, results='hide'}
shapiro.test(mix.model$aov$`subj:treatment`$residuals)

hist(mix.model$aov$`subj:treatment`$residuals
     , xlab = 'Residuals'
     , main = 'Histogram of residuals')
```
```{r, echo=FALSE, eval=TRUE}
shapiro.test(mix.model$aov$`subj:treatment`$residuals)
hist(mix.model$aov$`subj:treatment`$residuals, xlab = 'Residuals', main = 'Histogram of residuals')
```

Test assumption of sphericity
```{r}
mix.model$`Mauchly's Test for Sphericity`
```

### Running the test
If the assumption of sphericity is met use the normal, uncorrected ANOVA output
```{r}
mix.model$ANOVA
```

If the assumption of sphericity is violated, use the corrected ANOVA output
(The Greenhouse-Geisser correction is more conservative than the Huynd-Feldt correction)
```{r}
mix.model$`Sphericity Corrections`
```

### Post-hoc analysis

When there are one or more significant main-effects but no significant interaction effect post-hoc comparisons can be made using the pairwise.t.test() function.

Post-hoc comparison for the between-subjects factor:
```{r}
pairwise.t.test(
  x=data.long$score               # column name of the dependent variable
, g=data.long$gender              # column name of the independent between-subjects variable
, paired = TRUE                   # for the within factor, set paired=TRUE
, p.adjust.method = 'bonferroni'  # use bonferroni corrected p-values
)
```

Post-hoc comparison for the within-subjects factor:
```{r}
pairwise.t.test(
  x=data.long$score               # column name of the dependent variable
, g=data.long$treatment           # column name of the independent within-subjects variable
, paired = TRUE                   # for the within factor, set paired=TRUE
, p.adjust.method = 'bonferroni'  # use bonferroni corrected p-values
)
```

When the interaction-effect turns out significant, pairwise comparisons within each factor are not very informative about what the interaction looks like. Pairwise t-tests between all combinations of conditions is inappropriate when dealing with mixed designs. The best way to interpret an interaction effect is by looking at the interaction pattern in the data using descriptive statistics and visualization.
:::

## Visualisation
```{r}
cat_plot(model = model, 
              pred = treatment, 
              modx = gender, 
              plot.points = TRUE, 
              interval = TRUE, 
              jitter = 0.2)
```

